{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011267,
     "end_time": "2021-06-03T13:18:16.507530",
     "exception": false,
     "start_time": "2021-06-03T13:18:16.496263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Credit\n",
    "\n",
    "This notebook is based on the following notebook by @yasufuminakama. I would like to take this opportunity to thank him.\n",
    "\n",
    "Please vote for his notebook as well.\n",
    "\n",
    "https://www.kaggle.com/yasufuminakama/cassava-resnext50-32x4d-starter-training\n",
    "\n",
    "# Summary of this notebook\n",
    "\n",
    "In this notebook, we are gonna build the nocall detector. (0:nocall, 1:somebird singing)\n",
    "\n",
    "The output of the models would be probability value.\n",
    "\n",
    "# input & output of this notebook\n",
    "\n",
    "[input]\n",
    "\n",
    "freefield1010 data\n",
    "\n",
    "https://www.kaggle.com/startjapan/ff1010bird-duration7\n",
    "\n",
    "[output]\n",
    "\n",
    "Nocall detector models are outputted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:16.537460Z",
     "iopub.status.busy": "2021-06-03T13:18:16.536974Z",
     "iopub.status.idle": "2021-06-03T13:18:16.540823Z",
     "shell.execute_reply": "2021-06-03T13:18:16.540348Z"
    },
    "papermill": {
     "duration": 0.023365,
     "end_time": "2021-06-03T13:18:16.540951",
     "exception": false,
     "start_time": "2021-06-03T13:18:16.517586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torchsummary import summary\n",
    "\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:16.566791Z",
     "iopub.status.busy": "2021-06-03T13:18:16.566088Z",
     "iopub.status.idle": "2021-06-03T13:18:17.801738Z",
     "shell.execute_reply": "2021-06-03T13:18:17.801136Z"
    },
    "papermill": {
     "duration": 1.250811,
     "end_time": "2021-06-03T13:18:17.801878",
     "exception": false,
     "start_time": "2021-06-03T13:18:16.551067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CFG:\n",
    "    print_freq=100\n",
    "    num_workers=4\n",
    "    model_name= 'resnext50_32x4d'\n",
    "    dim=(128, 281)\n",
    "    scheduler='CosineAnnealingWarmRestarts'\n",
    "    epochs=20\n",
    "    lr=1e-4\n",
    "    T_0=10 # for CosineAnnealingWarmRestarts\n",
    "    min_lr=5e-7 # for CosineAnnealingWarmRestarts\n",
    "    batch_size=32\n",
    "    weight_decay=1e-6\n",
    "    max_grad_norm=1000\n",
    "    seed=42\n",
    "    target_size=2\n",
    "    target_col='hasbird'\n",
    "    n_fold = 5\n",
    "    pretrained = True\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:17.830157Z",
     "iopub.status.busy": "2021-06-03T13:18:17.829448Z",
     "iopub.status.idle": "2021-06-03T13:18:18.811434Z",
     "shell.execute_reply": "2021-06-03T13:18:18.810978Z"
    },
    "papermill": {
     "duration": 0.999064,
     "end_time": "2021-06-03T13:18:18.811555",
     "exception": false,
     "start_time": "2021-06-03T13:18:17.812491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  hasbird\n",
      "0     0          1151\n",
      "      1           387\n",
      "1     0          1151\n",
      "      1           387\n",
      "2     0          1151\n",
      "      1           387\n",
      "3     0          1151\n",
      "      1           387\n",
      "4     0          1151\n",
      "      1           387\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('../../input/rich_metadata.csv')\n",
    "train.loc[train['hasbird']==0, 'filepath'] = '../../input/nocall/' + train.query('hasbird==0')['filename'] + '.npy'\n",
    "train.loc[train['hasbird']==1, 'filepath'] = '../../input/bird/' + train.query('hasbird==1')['filename'] + '.npy'\n",
    "\n",
    "train = train.dropna().reset_index(drop=True)\n",
    "\n",
    "folds = train.copy()\n",
    "Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[CFG.target_col])):\n",
    "    folds.loc[val_index, 'fold'] = int(n)\n",
    "folds['fold'] = folds['fold'].astype(int)\n",
    "print(folds.groupby(['fold', CFG.target_col]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:18.844986Z",
     "iopub.status.busy": "2021-06-03T13:18:18.844348Z",
     "iopub.status.idle": "2021-06-03T13:18:28.957198Z",
     "shell.execute_reply": "2021-06-03T13:18:28.956722Z"
    },
    "papermill": {
     "duration": 10.134555,
     "end_time": "2021-06-03T13:18:28.957330",
     "exception": false,
     "start_time": "2021-06-03T13:18:18.822775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "\n",
    "#!pip install timm\n",
    "import timm\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:28.992535Z",
     "iopub.status.busy": "2021-06-03T13:18:28.991939Z",
     "iopub.status.idle": "2021-06-03T13:18:28.998314Z",
     "shell.execute_reply": "2021-06-03T13:18:28.997883Z"
    },
    "papermill": {
     "duration": 0.028265,
     "end_time": "2021-06-03T13:18:28.998451",
     "exception": false,
     "start_time": "2021-06-03T13:18:28.970186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "def get_confusion_matrix(y_true, y_pred):\n",
    "    return confusion_matrix(y_true, y_pred)\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f'[{name}] start')\n",
    "    yield\n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:29.031990Z",
     "iopub.status.busy": "2021-06-03T13:18:29.031227Z",
     "iopub.status.idle": "2021-06-03T13:18:29.033990Z",
     "shell.execute_reply": "2021-06-03T13:18:29.033586Z"
    },
    "papermill": {
     "duration": 0.022696,
     "end_time": "2021-06-03T13:18:29.034100",
     "exception": false,
     "start_time": "2021-06-03T13:18:29.011404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_paths = df['filepath'].values\n",
    "        self.labels = df['hasbird'].values\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_paths[idx]\n",
    "        file_path = file_name\n",
    "        image = np.load(file_path)\n",
    "        image = image.transpose(1,2,0)\n",
    "        image = np.squeeze(image)\n",
    "        image = np.stack((image,)*3, -1)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        label = torch.tensor(self.labels[idx]).long()\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:29.065650Z",
     "iopub.status.busy": "2021-06-03T13:18:29.064968Z",
     "iopub.status.idle": "2021-06-03T13:18:29.067798Z",
     "shell.execute_reply": "2021-06-03T13:18:29.067278Z"
    },
    "papermill": {
     "duration": 0.021515,
     "end_time": "2021-06-03T13:18:29.067897",
     "exception": false,
     "start_time": "2021-06-03T13:18:29.046382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_transforms(*, data):\n",
    "    \n",
    "    if data == 'train':\n",
    "        return A.Compose([\n",
    "            A.Resize(CFG.dim[0], CFG.dim[1]),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.augmentations.transforms.JpegCompression(p=0.5),\n",
    "            A.augmentations.transforms.ImageCompression(p=0.5, compression_type=A.augmentations.transforms.ImageCompression.ImageCompressionType.WEBP),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    elif data == 'valid':\n",
    "        return A.Compose([\n",
    "            A.Resize(CFG.dim[0], CFG.dim[1]),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:29.097673Z",
     "iopub.status.busy": "2021-06-03T13:18:29.096993Z",
     "iopub.status.idle": "2021-06-03T13:18:29.099748Z",
     "shell.execute_reply": "2021-06-03T13:18:29.099238Z"
    },
    "papermill": {
     "duration": 0.019641,
     "end_time": "2021-06-03T13:18:29.099847",
     "exception": false,
     "start_time": "2021-06-03T13:18:29.080206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomResNext(nn.Module):\n",
    "    def __init__(self, model_name='resnext50_32x4d', pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        n_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:29.145766Z",
     "iopub.status.busy": "2021-06-03T13:18:29.144984Z",
     "iopub.status.idle": "2021-06-03T13:18:29.147597Z",
     "shell.execute_reply": "2021-06-03T13:18:29.147086Z"
    },
    "papermill": {
     "duration": 0.035666,
     "end_time": "2021-06-03T13:18:29.147696",
     "exception": false,
     "start_time": "2021-06-03T13:18:29.112030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (images, labels) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        y_preds = model(images)\n",
    "        loss = criterion(y_preds, labels)\n",
    "        # record loss\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        global_step += 1\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  .format(\n",
    "                   epoch+1, step+1, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses,\n",
    "                   remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                   grad_norm=grad_norm,\n",
    "                   ))\n",
    "    return losses.avg\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (images, labels) in enumerate(valid_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(images)\n",
    "        loss = criterion(y_preds, labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        # record accuracy\n",
    "        preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(\n",
    "                   step+1, len(valid_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses,\n",
    "                   remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                   ))\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions\n",
    "\n",
    "def inference(model, states, test_loader, device):\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    probs = []\n",
    "    for i, (images) in tk0:\n",
    "        images = images.to(device)\n",
    "        avg_preds = []\n",
    "        for state in states:\n",
    "            model.load_state_dict(state['model'])\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "        avg_preds = np.mean(avg_preds, axis=0)\n",
    "        probs.append(avg_preds)\n",
    "    probs = np.concatenate(probs)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:29.187429Z",
     "iopub.status.busy": "2021-06-03T13:18:29.186604Z",
     "iopub.status.idle": "2021-06-03T13:18:29.189566Z",
     "shell.execute_reply": "2021-06-03T13:18:29.189044Z"
    },
    "papermill": {
     "duration": 0.029536,
     "end_time": "2021-06-03T13:18:29.189694",
     "exception": false,
     "start_time": "2021-06-03T13:18:29.160158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(train_folds, valid_folds):\n",
    "\n",
    "    LOGGER.info(f\"========== training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    train_dataset = TrainDataset(train_folds, \n",
    "                                 transform=get_transforms(data='train'))\n",
    "    valid_dataset = TrainDataset(valid_folds, \n",
    "                                 transform=get_transforms(data='valid'))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, \n",
    "                              batch_size=CFG.batch_size, \n",
    "                              shuffle=False, \n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, \n",
    "                              batch_size=CFG.batch_size, \n",
    "                              shuffle=False, \n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "    \n",
    "    def get_scheduler(optimizer):\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = CustomResNext(CFG.model_name, pretrained=True)\n",
    "    model.to(CFG.device)\n",
    "\n",
    "    summary(model, (3, 128, 128))\n",
    "\n",
    "    \n",
    "    optimizer = Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay, amsgrad=False)\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "    criterion = nn.NLLLoss()\n",
    "    best_score = 0.\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for epoch in range(CFG.epochs):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, CFG.device)\n",
    "        \n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, CFG.device)\n",
    "        valid_labels = valid_folds[CFG.target_col].values\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        score = get_score(valid_labels, preds.argmax(1))\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Accuracy: {score}')\n",
    "        \n",
    "        scores.append(score)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(), \n",
    "                        'preds': preds},\n",
    "                        OUTPUT_DIR+f'{CFG.model_name}_best.pth')\n",
    "    \n",
    "    check_point = torch.load(OUTPUT_DIR+f'{CFG.model_name}_best.pth')\n",
    "    valid_folds[[str(c) for c in range(CFG.target_size)]] = check_point['preds']\n",
    "    valid_folds['preds'] = check_point['preds'].argmax(1)\n",
    "\n",
    "    return valid_folds, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:29.221823Z",
     "iopub.status.busy": "2021-06-03T13:18:29.221144Z",
     "iopub.status.idle": "2021-06-03T13:18:29.223394Z",
     "shell.execute_reply": "2021-06-03T13:18:29.223813Z"
    },
    "papermill": {
     "duration": 0.022003,
     "end_time": "2021-06-03T13:18:29.223933",
     "exception": false,
     "start_time": "2021-06-03T13:18:29.201930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(fold):\n",
    "    def get_result(result_df):\n",
    "        preds = result_df['preds'].values\n",
    "        labels = result_df[CFG.target_col].values\n",
    "        score = get_score(labels, preds)\n",
    "        LOGGER.info(f'Score: {score:<.5f}')\n",
    "    \n",
    "    def get_result2(result_df):\n",
    "        preds = result_df['preds'].values\n",
    "        labels = result_df[CFG.target_col].values\n",
    "        matrix = get_confusion_matrix(labels, preds)\n",
    "        print('TN', matrix[0,0])\n",
    "        print('FP', matrix[0,1])\n",
    "        print('FN', matrix[1,0])\n",
    "        print('TP', matrix[1,1])\n",
    "    \n",
    "    # train \n",
    "    train_folds = folds.query(f'fold!={fold}').reset_index(drop=True)\n",
    "    valid_folds = folds.query(f'fold=={fold}').reset_index(drop=False)\n",
    "    oof_df, scores = train_loop(train_folds, valid_folds)\n",
    "    # CV result\n",
    "    LOGGER.info(f\"========== CV ==========\")\n",
    "    get_result(oof_df)\n",
    "    get_result2(oof_df)\n",
    "    # save result\n",
    "    oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)\n",
    "    plt.plot([i for i in range(CFG.epochs)], scores)\n",
    "    plt.title('valid score')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:29.255472Z",
     "iopub.status.busy": "2021-06-03T13:18:29.254659Z",
     "iopub.status.idle": "2021-06-03T13:33:30.200216Z",
     "shell.execute_reply": "2021-06-03T13:33:30.199729Z"
    },
    "papermill": {
     "duration": 900.96416,
     "end_time": "2021-06-03T13:33:30.200354",
     "exception": false,
     "start_time": "2021-06-03T13:18:29.236194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== training ==========\n",
      "========== training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
      "              ReLU-3           [-1, 64, 64, 64]               0\n",
      "         MaxPool2d-4           [-1, 64, 32, 32]               0\n",
      "            Conv2d-5          [-1, 128, 32, 32]           8,192\n",
      "       BatchNorm2d-6          [-1, 128, 32, 32]             256\n",
      "              ReLU-7          [-1, 128, 32, 32]               0\n",
      "            Conv2d-8          [-1, 128, 32, 32]           4,608\n",
      "       BatchNorm2d-9          [-1, 128, 32, 32]             256\n",
      "             ReLU-10          [-1, 128, 32, 32]               0\n",
      "           Conv2d-11          [-1, 256, 32, 32]          32,768\n",
      "      BatchNorm2d-12          [-1, 256, 32, 32]             512\n",
      "           Conv2d-13          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 32, 32]             512\n",
      "             ReLU-15          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-16          [-1, 256, 32, 32]               0\n",
      "           Conv2d-17          [-1, 128, 32, 32]          32,768\n",
      "      BatchNorm2d-18          [-1, 128, 32, 32]             256\n",
      "             ReLU-19          [-1, 128, 32, 32]               0\n",
      "           Conv2d-20          [-1, 128, 32, 32]           4,608\n",
      "      BatchNorm2d-21          [-1, 128, 32, 32]             256\n",
      "             ReLU-22          [-1, 128, 32, 32]               0\n",
      "           Conv2d-23          [-1, 256, 32, 32]          32,768\n",
      "      BatchNorm2d-24          [-1, 256, 32, 32]             512\n",
      "             ReLU-25          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-26          [-1, 256, 32, 32]               0\n",
      "           Conv2d-27          [-1, 128, 32, 32]          32,768\n",
      "      BatchNorm2d-28          [-1, 128, 32, 32]             256\n",
      "             ReLU-29          [-1, 128, 32, 32]               0\n",
      "           Conv2d-30          [-1, 128, 32, 32]           4,608\n",
      "      BatchNorm2d-31          [-1, 128, 32, 32]             256\n",
      "             ReLU-32          [-1, 128, 32, 32]               0\n",
      "           Conv2d-33          [-1, 256, 32, 32]          32,768\n",
      "      BatchNorm2d-34          [-1, 256, 32, 32]             512\n",
      "             ReLU-35          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-36          [-1, 256, 32, 32]               0\n",
      "           Conv2d-37          [-1, 256, 32, 32]          65,536\n",
      "      BatchNorm2d-38          [-1, 256, 32, 32]             512\n",
      "             ReLU-39          [-1, 256, 32, 32]               0\n",
      "           Conv2d-40          [-1, 256, 16, 16]          18,432\n",
      "      BatchNorm2d-41          [-1, 256, 16, 16]             512\n",
      "             ReLU-42          [-1, 256, 16, 16]               0\n",
      "           Conv2d-43          [-1, 512, 16, 16]         131,072\n",
      "      BatchNorm2d-44          [-1, 512, 16, 16]           1,024\n",
      "           Conv2d-45          [-1, 512, 16, 16]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-47          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-48          [-1, 512, 16, 16]               0\n",
      "           Conv2d-49          [-1, 256, 16, 16]         131,072\n",
      "      BatchNorm2d-50          [-1, 256, 16, 16]             512\n",
      "             ReLU-51          [-1, 256, 16, 16]               0\n",
      "           Conv2d-52          [-1, 256, 16, 16]          18,432\n",
      "      BatchNorm2d-53          [-1, 256, 16, 16]             512\n",
      "             ReLU-54          [-1, 256, 16, 16]               0\n",
      "           Conv2d-55          [-1, 512, 16, 16]         131,072\n",
      "      BatchNorm2d-56          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-57          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-58          [-1, 512, 16, 16]               0\n",
      "           Conv2d-59          [-1, 256, 16, 16]         131,072\n",
      "      BatchNorm2d-60          [-1, 256, 16, 16]             512\n",
      "             ReLU-61          [-1, 256, 16, 16]               0\n",
      "           Conv2d-62          [-1, 256, 16, 16]          18,432\n",
      "      BatchNorm2d-63          [-1, 256, 16, 16]             512\n",
      "             ReLU-64          [-1, 256, 16, 16]               0\n",
      "           Conv2d-65          [-1, 512, 16, 16]         131,072\n",
      "      BatchNorm2d-66          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-67          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-68          [-1, 512, 16, 16]               0\n",
      "           Conv2d-69          [-1, 256, 16, 16]         131,072\n",
      "      BatchNorm2d-70          [-1, 256, 16, 16]             512\n",
      "             ReLU-71          [-1, 256, 16, 16]               0\n",
      "           Conv2d-72          [-1, 256, 16, 16]          18,432\n",
      "      BatchNorm2d-73          [-1, 256, 16, 16]             512\n",
      "             ReLU-74          [-1, 256, 16, 16]               0\n",
      "           Conv2d-75          [-1, 512, 16, 16]         131,072\n",
      "      BatchNorm2d-76          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-77          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-78          [-1, 512, 16, 16]               0\n",
      "           Conv2d-79          [-1, 512, 16, 16]         262,144\n",
      "      BatchNorm2d-80          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-81          [-1, 512, 16, 16]               0\n",
      "           Conv2d-82            [-1, 512, 8, 8]          73,728\n",
      "      BatchNorm2d-83            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-84            [-1, 512, 8, 8]               0\n",
      "           Conv2d-85           [-1, 1024, 8, 8]         524,288\n",
      "      BatchNorm2d-86           [-1, 1024, 8, 8]           2,048\n",
      "           Conv2d-87           [-1, 1024, 8, 8]         524,288\n",
      "      BatchNorm2d-88           [-1, 1024, 8, 8]           2,048\n",
      "             ReLU-89           [-1, 1024, 8, 8]               0\n",
      "       Bottleneck-90           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-91            [-1, 512, 8, 8]         524,288\n",
      "      BatchNorm2d-92            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-93            [-1, 512, 8, 8]               0\n",
      "           Conv2d-94            [-1, 512, 8, 8]          73,728\n",
      "      BatchNorm2d-95            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-96            [-1, 512, 8, 8]               0\n",
      "           Conv2d-97           [-1, 1024, 8, 8]         524,288\n",
      "      BatchNorm2d-98           [-1, 1024, 8, 8]           2,048\n",
      "             ReLU-99           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-100           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-101            [-1, 512, 8, 8]         524,288\n",
      "     BatchNorm2d-102            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-103            [-1, 512, 8, 8]               0\n",
      "          Conv2d-104            [-1, 512, 8, 8]          73,728\n",
      "     BatchNorm2d-105            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-106            [-1, 512, 8, 8]               0\n",
      "          Conv2d-107           [-1, 1024, 8, 8]         524,288\n",
      "     BatchNorm2d-108           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-109           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-110           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-111            [-1, 512, 8, 8]         524,288\n",
      "     BatchNorm2d-112            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-113            [-1, 512, 8, 8]               0\n",
      "          Conv2d-114            [-1, 512, 8, 8]          73,728\n",
      "     BatchNorm2d-115            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-116            [-1, 512, 8, 8]               0\n",
      "          Conv2d-117           [-1, 1024, 8, 8]         524,288\n",
      "     BatchNorm2d-118           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-119           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-120           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-121            [-1, 512, 8, 8]         524,288\n",
      "     BatchNorm2d-122            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-123            [-1, 512, 8, 8]               0\n",
      "          Conv2d-124            [-1, 512, 8, 8]          73,728\n",
      "     BatchNorm2d-125            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-126            [-1, 512, 8, 8]               0\n",
      "          Conv2d-127           [-1, 1024, 8, 8]         524,288\n",
      "     BatchNorm2d-128           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-129           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-130           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-131            [-1, 512, 8, 8]         524,288\n",
      "     BatchNorm2d-132            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-133            [-1, 512, 8, 8]               0\n",
      "          Conv2d-134            [-1, 512, 8, 8]          73,728\n",
      "     BatchNorm2d-135            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-136            [-1, 512, 8, 8]               0\n",
      "          Conv2d-137           [-1, 1024, 8, 8]         524,288\n",
      "     BatchNorm2d-138           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-139           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-140           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-141           [-1, 1024, 8, 8]       1,048,576\n",
      "     BatchNorm2d-142           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-143           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-144           [-1, 1024, 4, 4]         294,912\n",
      "     BatchNorm2d-145           [-1, 1024, 4, 4]           2,048\n",
      "            ReLU-146           [-1, 1024, 4, 4]               0\n",
      "          Conv2d-147           [-1, 2048, 4, 4]       2,097,152\n",
      "     BatchNorm2d-148           [-1, 2048, 4, 4]           4,096\n",
      "          Conv2d-149           [-1, 2048, 4, 4]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 4, 4]           4,096\n",
      "            ReLU-151           [-1, 2048, 4, 4]               0\n",
      "      Bottleneck-152           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-153           [-1, 1024, 4, 4]       2,097,152\n",
      "     BatchNorm2d-154           [-1, 1024, 4, 4]           2,048\n",
      "            ReLU-155           [-1, 1024, 4, 4]               0\n",
      "          Conv2d-156           [-1, 1024, 4, 4]         294,912\n",
      "     BatchNorm2d-157           [-1, 1024, 4, 4]           2,048\n",
      "            ReLU-158           [-1, 1024, 4, 4]               0\n",
      "          Conv2d-159           [-1, 2048, 4, 4]       2,097,152\n",
      "     BatchNorm2d-160           [-1, 2048, 4, 4]           4,096\n",
      "            ReLU-161           [-1, 2048, 4, 4]               0\n",
      "      Bottleneck-162           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-163           [-1, 1024, 4, 4]       2,097,152\n",
      "     BatchNorm2d-164           [-1, 1024, 4, 4]           2,048\n",
      "            ReLU-165           [-1, 1024, 4, 4]               0\n",
      "          Conv2d-166           [-1, 1024, 4, 4]         294,912\n",
      "     BatchNorm2d-167           [-1, 1024, 4, 4]           2,048\n",
      "            ReLU-168           [-1, 1024, 4, 4]               0\n",
      "          Conv2d-169           [-1, 2048, 4, 4]       2,097,152\n",
      "     BatchNorm2d-170           [-1, 2048, 4, 4]           4,096\n",
      "            ReLU-171           [-1, 2048, 4, 4]               0\n",
      "      Bottleneck-172           [-1, 2048, 4, 4]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "         Flatten-174                 [-1, 2048]               0\n",
      "SelectAdaptivePool2d-175                 [-1, 2048]               0\n",
      "          Linear-176                    [-1, 2]           4,098\n",
      "          ResNet-177                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 22,984,002\n",
      "Trainable params: 22,984,002\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 118.17\n",
      "Params size (MB): 87.68\n",
      "Estimated Total Size (MB): 206.04\n",
      "----------------------------------------------------------------\n",
      "Epoch: [1][1/192] Data 0.516 (0.516) Elapsed 0m 1s (remain 4m 23s) Loss: -0.1161(-0.1161) Grad: 27.1537  \n",
      "Epoch: [1][101/192] Data 0.000 (0.005) Elapsed 0m 20s (remain 0m 18s) Loss: -41.1677(-16.6872) Grad: 98.3974  \n",
      "Epoch: [1][192/192] Data 0.000 (0.003) Elapsed 0m 38s (remain 0m 0s) Loss: -74.2537(-36.8043) Grad: 416.6884  \n",
      "EVAL: [1/49] Data 0.148 (0.148) Elapsed 0m 0s (remain 0m 10s) Loss: -80.3334(-80.3334) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: -36.8043  avg_val_loss: -68.4373  time: 42s\n",
      "Epoch 1 - avg_train_loss: -36.8043  avg_val_loss: -68.4373  time: 42s\n",
      "Epoch 1 - Accuracy: 0.8654096228868661\n",
      "Epoch 1 - Accuracy: 0.8654096228868661\n",
      "Epoch 1 - Save Best Score: 0.8654 Model\n",
      "Epoch 1 - Save Best Score: 0.8654 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [49/49] Data 0.000 (0.004) Elapsed 0m 3s (remain 0m 0s) Loss: -46.3937(-68.4373) \n",
      "Epoch: [2][1/192] Data 0.624 (0.624) Elapsed 0m 0s (remain 2m 32s) Loss: -69.5183(-69.5183) Grad: 233.4034  \n",
      "Epoch: [2][101/192] Data 0.001 (0.007) Elapsed 0m 20s (remain 0m 18s) Loss: -107.9924(-91.6976) Grad: 164.5726  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.033439,
     "end_time": "2021-06-03T13:33:30.267988",
     "exception": false,
     "start_time": "2021-06-03T13:33:30.234549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 921.862366,
   "end_time": "2021-06-03T13:33:31.832533",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-03T13:18:09.970167",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
