{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011267,
     "end_time": "2021-06-03T13:18:16.507530",
     "exception": false,
     "start_time": "2021-06-03T13:18:16.496263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Credit\n",
    "\n",
    "This notebook is based on the following notebook by @yasufuminakama. I would like to take this opportunity to thank him.\n",
    "\n",
    "Please vote for his notebook as well.\n",
    "\n",
    "https://www.kaggle.com/yasufuminakama/cassava-resnext50-32x4d-starter-training\n",
    "\n",
    "# Summary of this notebook\n",
    "\n",
    "In this notebook, we are gonna build the nocall detector. (0:nocall, 1:somebird singing)\n",
    "\n",
    "The output of the models would be probability value.\n",
    "\n",
    "# input & output of this notebook\n",
    "\n",
    "[input]\n",
    "\n",
    "freefield1010 data\n",
    "\n",
    "https://www.kaggle.com/startjapan/ff1010bird-duration7\n",
    "\n",
    "[output]\n",
    "\n",
    "Nocall detector models are outputted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:16.537460Z",
     "iopub.status.busy": "2021-06-03T13:18:16.536974Z",
     "iopub.status.idle": "2021-06-03T13:18:16.540823Z",
     "shell.execute_reply": "2021-06-03T13:18:16.540348Z"
    },
    "papermill": {
     "duration": 0.023365,
     "end_time": "2021-06-03T13:18:16.540951",
     "exception": false,
     "start_time": "2021-06-03T13:18:16.517586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:16.566791Z",
     "iopub.status.busy": "2021-06-03T13:18:16.566088Z",
     "iopub.status.idle": "2021-06-03T13:18:17.801738Z",
     "shell.execute_reply": "2021-06-03T13:18:17.801136Z"
    },
    "papermill": {
     "duration": 1.250811,
     "end_time": "2021-06-03T13:18:17.801878",
     "exception": false,
     "start_time": "2021-06-03T13:18:16.551067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CFG:\n",
    "    print_freq=100\n",
    "    num_workers=4\n",
    "    model_name= 'resnext50_32x4d'\n",
    "    dim=(128, 281)\n",
    "    scheduler='CosineAnnealingWarmRestarts'\n",
    "    epochs=20\n",
    "    lr=1e-4\n",
    "    T_0=10 # for CosineAnnealingWarmRestarts\n",
    "    min_lr=5e-7 # for CosineAnnealingWarmRestarts\n",
    "    batch_size=32\n",
    "    weight_decay=1e-6\n",
    "    max_grad_norm=1000\n",
    "    seed=42\n",
    "    target_size=2\n",
    "    target_col='hasbird'\n",
    "    n_fold = 5\n",
    "    pretrained = True\n",
    "    #device = 'cpu'\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:17.830157Z",
     "iopub.status.busy": "2021-06-03T13:18:17.829448Z",
     "iopub.status.idle": "2021-06-03T13:18:18.811434Z",
     "shell.execute_reply": "2021-06-03T13:18:18.810978Z"
    },
    "papermill": {
     "duration": 0.999064,
     "end_time": "2021-06-03T13:18:18.811555",
     "exception": false,
     "start_time": "2021-06-03T13:18:17.812491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  hasbird\n",
      "0     0          1151\n",
      "      1           387\n",
      "1     0          1151\n",
      "      1           387\n",
      "2     0          1151\n",
      "      1           387\n",
      "3     0          1151\n",
      "      1           387\n",
      "4     0          1151\n",
      "      1           387\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('../../input/rich_metadata.csv')\n",
    "train.loc[train['hasbird']==0, 'filepath'] = '../../input/nocall/' + train.query('hasbird==0')['filename'] + '.npy'\n",
    "train.loc[train['hasbird']==1, 'filepath'] = '../../input/bird/' + train.query('hasbird==1')['filename'] + '.npy'\n",
    "\n",
    "train = train.dropna().reset_index(drop=True)\n",
    "\n",
    "folds = train.copy()\n",
    "Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[CFG.target_col])):\n",
    "    folds.loc[val_index, 'fold'] = int(n)\n",
    "folds['fold'] = folds['fold'].astype(int)\n",
    "print(folds.groupby(['fold', CFG.target_col]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:18.844986Z",
     "iopub.status.busy": "2021-06-03T13:18:18.844348Z",
     "iopub.status.idle": "2021-06-03T13:18:28.957198Z",
     "shell.execute_reply": "2021-06-03T13:18:28.956722Z"
    },
    "papermill": {
     "duration": 10.134555,
     "end_time": "2021-06-03T13:18:28.957330",
     "exception": false,
     "start_time": "2021-06-03T13:18:18.822775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: timm in /home/next/.local/lib/python3.10/site-packages (0.4.12)\n",
      "Requirement already satisfied: torch>=1.4 in /home/next/.local/lib/python3.10/site-packages (from timm) (2.0.1)\n",
      "Requirement already satisfied: torchvision in /home/next/.local/lib/python3.10/site-packages (from timm) (0.15.2)\n",
      "Requirement already satisfied: filelock in /home/next/.local/lib/python3.10/site-packages (from torch>=1.4->timm) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /home/next/.local/lib/python3.10/site-packages (from torch>=1.4->timm) (4.7.1)\n",
      "Requirement already satisfied: sympy in /home/next/.local/lib/python3.10/site-packages (from torch>=1.4->timm) (1.12)\n",
      "Requirement already satisfied: networkx in /home/next/.local/lib/python3.10/site-packages (from torch>=1.4->timm) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in /home/next/.local/lib/python3.10/site-packages (from torch>=1.4->timm) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/next/.local/lib/python3.10/site-packages (from torch>=1.4->timm) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/next/.local/lib/python3.10/site-packages (from torch>=1.4->timm) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/next/.local/lib/python3.10/site-packages (from torch>=1.4->timm) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/next/.local/lib/python3.10/site-packages (from torch>=1.4->timm) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/next/.local/lib/python3.10/site-packages (from torch>=1.4->timm) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/next/.local/lib/python3.10/site-packages (from torch>=1.4->timm) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/next/.local/lib/python3.10/site-packages (from torch>=1.4->timm) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/next/.local/lib/python3.10/site-packages (from torch>=1.4->timm) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/next/.local/lib/python3.10/site-packages (from torch>=1.4->timm) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/next/.local/lib/python3.10/site-packages (from torch>=1.4->timm) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/next/.local/lib/python3.10/site-packages (from torch>=1.4->timm) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/next/.local/lib/python3.10/site-packages (from torch>=1.4->timm) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/next/.local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4->timm) (65.5.1)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4->timm) (0.37.1)\n",
      "Requirement already satisfied: cmake in /home/next/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.4->timm) (3.27.2)\n",
      "Requirement already satisfied: lit in /home/next/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.4->timm) (16.0.6)\n",
      "Requirement already satisfied: numpy in /home/next/.local/lib/python3.10/site-packages (from torchvision->timm) (1.23.5)\n",
      "Requirement already satisfied: requests in /home/next/.local/lib/python3.10/site-packages (from torchvision->timm) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/next/.local/lib/python3.10/site-packages (from torchvision->timm) (10.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/next/.local/lib/python3.10/site-packages (from jinja2->torch>=1.4->timm) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/next/.local/lib/python3.10/site-packages (from requests->torchvision->timm) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/next/.local/lib/python3.10/site-packages (from requests->torchvision->timm) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/next/.local/lib/python3.10/site-packages (from requests->torchvision->timm) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/next/.local/lib/python3.10/site-packages (from requests->torchvision->timm) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/next/.local/lib/python3.10/site-packages (from sympy->torch>=1.4->timm) (1.3.0)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.6.5 has a non-standard dependency specifier torch>=1.8.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "\n",
    "!pip install timm\n",
    "import timm\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:28.992535Z",
     "iopub.status.busy": "2021-06-03T13:18:28.991939Z",
     "iopub.status.idle": "2021-06-03T13:18:28.998314Z",
     "shell.execute_reply": "2021-06-03T13:18:28.997883Z"
    },
    "papermill": {
     "duration": 0.028265,
     "end_time": "2021-06-03T13:18:28.998451",
     "exception": false,
     "start_time": "2021-06-03T13:18:28.970186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "def get_confusion_matrix(y_true, y_pred):\n",
    "    return confusion_matrix(y_true, y_pred)\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f'[{name}] start')\n",
    "    yield\n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:29.031990Z",
     "iopub.status.busy": "2021-06-03T13:18:29.031227Z",
     "iopub.status.idle": "2021-06-03T13:18:29.033990Z",
     "shell.execute_reply": "2021-06-03T13:18:29.033586Z"
    },
    "papermill": {
     "duration": 0.022696,
     "end_time": "2021-06-03T13:18:29.034100",
     "exception": false,
     "start_time": "2021-06-03T13:18:29.011404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_paths = df['filepath'].values\n",
    "        self.labels = df['hasbird'].values\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_paths[idx]\n",
    "        file_path = file_name\n",
    "        image = np.load(file_path)\n",
    "        image = image.transpose(1,2,0)\n",
    "        image = np.squeeze(image)\n",
    "        image = np.stack((image,)*3, -1)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        label = torch.tensor(self.labels[idx]).long()\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:29.065650Z",
     "iopub.status.busy": "2021-06-03T13:18:29.064968Z",
     "iopub.status.idle": "2021-06-03T13:18:29.067798Z",
     "shell.execute_reply": "2021-06-03T13:18:29.067278Z"
    },
    "papermill": {
     "duration": 0.021515,
     "end_time": "2021-06-03T13:18:29.067897",
     "exception": false,
     "start_time": "2021-06-03T13:18:29.046382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_transforms(*, data):\n",
    "    \n",
    "    if data == 'train':\n",
    "        return A.Compose([\n",
    "            A.Resize(CFG.dim[0], CFG.dim[1]),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.augmentations.transforms.JpegCompression(p=0.5),\n",
    "            A.augmentations.transforms.ImageCompression(p=0.5, compression_type=A.augmentations.transforms.ImageCompression.ImageCompressionType.WEBP),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    elif data == 'valid':\n",
    "        return A.Compose([\n",
    "            A.Resize(CFG.dim[0], CFG.dim[1]),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af7c554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomResNext(nn.Module):\n",
    "    def __init__(self, model_name='resnext50_32x4d', pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        n_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a938703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, CrossEntropyLoss, MSELoss\n",
    "from torch.optim import LBFGS\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.utils import algorithm_globals\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "# Set seed for random generators\n",
    "algorithm_globals.random_seed = 42\n",
    "\n",
    "# we decompose the circuit for the QNN to avoid additional data copying\n",
    "# Define and create QNN\n",
    "nq=2\n",
    "def create_qnn():\n",
    "    feature_map = ZZFeatureMap(nq)\n",
    "    ansatz = RealAmplitudes(nq, reps=1)\n",
    "    qc = QuantumCircuit(nq)\n",
    "    qc.compose(feature_map, inplace=True)\n",
    "    qc.compose(ansatz, inplace=True)\n",
    "\n",
    "    # REMEMBER TO SET input_gradients=True FOR ENABLING HYBRID GRADIENT BACKPROP\n",
    "    qnn = SamplerQNN(\n",
    "        circuit=qc,\n",
    "        input_params=feature_map.parameters,\n",
    "        weight_params=ansatz.parameters,\n",
    "        input_gradients=True,\n",
    "    )\n",
    "    return qnn\n",
    "\n",
    "\n",
    "qnn4 = create_qnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59643d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from torch import cat, no_grad, manual_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "431e8931",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumCustomResNext(nn.Module):\n",
    "    def __init__(self, model_name='resnext50_32x4d', pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        #self.fc = nn.Linear(512, nq)    \n",
    "        #self.qnn = TorchConnector(qnn4)\n",
    "        #self.fc2 = nn.Linear(pow(2, nq), CFG.target_size)\n",
    "        \n",
    "        # Remove fully connected layer and last two blocks\n",
    "        #self.model.fc = nn.Identity()\n",
    "        #self.model.layer4 = nn.Identity()\n",
    "        #self.model.layer3 = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        #x = self.fc(x)\n",
    "        #x = self.qnn(x)\n",
    "        #x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:29.145766Z",
     "iopub.status.busy": "2021-06-03T13:18:29.144984Z",
     "iopub.status.idle": "2021-06-03T13:18:29.147597Z",
     "shell.execute_reply": "2021-06-03T13:18:29.147086Z"
    },
    "papermill": {
     "duration": 0.035666,
     "end_time": "2021-06-03T13:18:29.147696",
     "exception": false,
     "start_time": "2021-06-03T13:18:29.112030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (images, labels) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        y_preds = model(images)\n",
    "        loss = criterion(y_preds, labels)\n",
    "        # record loss\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        global_step += 1\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  .format(\n",
    "                   epoch+1, step+1, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses,\n",
    "                   remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                   grad_norm=grad_norm,\n",
    "                   ))\n",
    "    return losses.avg\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (images, labels) in enumerate(valid_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(images)\n",
    "        loss = criterion(y_preds, labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        # record accuracy\n",
    "        preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(\n",
    "                   step+1, len(valid_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses,\n",
    "                   remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                   ))\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions\n",
    "\n",
    "def inference(model, states, test_loader, device):\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    probs = []\n",
    "    for i, (images) in tk0:\n",
    "        images = images.to(device)\n",
    "        avg_preds = []\n",
    "        for state in states:\n",
    "            model.load_state_dict(state['model'])\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "        avg_preds = np.mean(avg_preds, axis=0)\n",
    "        probs.append(avg_preds)\n",
    "    probs = np.concatenate(probs)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:29.187429Z",
     "iopub.status.busy": "2021-06-03T13:18:29.186604Z",
     "iopub.status.idle": "2021-06-03T13:18:29.189566Z",
     "shell.execute_reply": "2021-06-03T13:18:29.189044Z"
    },
    "papermill": {
     "duration": 0.029536,
     "end_time": "2021-06-03T13:18:29.189694",
     "exception": false,
     "start_time": "2021-06-03T13:18:29.160158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "def train_loop(train_folds, valid_folds):\n",
    "\n",
    "    LOGGER.info(f\"========== training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    train_dataset = TrainDataset(train_folds, \n",
    "                                 transform=get_transforms(data='train'))\n",
    "    valid_dataset = TrainDataset(valid_folds, \n",
    "                                 transform=get_transforms(data='valid'))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, \n",
    "                              batch_size=CFG.batch_size, \n",
    "                              shuffle=False, \n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, \n",
    "                              batch_size=CFG.batch_size, \n",
    "                              shuffle=False, \n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "    \n",
    "    def get_scheduler(optimizer):\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = QuantumCustomResNext(CFG.model_name, pretrained=True)\n",
    "    #model = CustomResNext(CFG.model_name, pretrained=True)\n",
    "    model.to(CFG.device)\n",
    "    \n",
    "    optimizer = Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay, amsgrad=False)\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #criterion = nn.NLLLoss()\n",
    "    best_score = 0.\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    summary(model, (3, 224, 224))\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for epoch in range(CFG.epochs):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, CFG.device)\n",
    "        \n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, CFG.device)\n",
    "        valid_labels = valid_folds[CFG.target_col].values\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        score = get_score(valid_labels, preds.argmax(1))\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Accuracy: {score}')\n",
    "        \n",
    "        scores.append(score)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(), \n",
    "                        'preds': preds},\n",
    "                        OUTPUT_DIR+f'{CFG.model_name}_best.pth')\n",
    "    \n",
    "    check_point = torch.load(OUTPUT_DIR+f'{CFG.model_name}_best.pth')\n",
    "    valid_folds[[str(c) for c in range(CFG.target_size)]] = check_point['preds']\n",
    "    valid_folds['preds'] = check_point['preds'].argmax(1)\n",
    "\n",
    "    return valid_folds, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:29.221823Z",
     "iopub.status.busy": "2021-06-03T13:18:29.221144Z",
     "iopub.status.idle": "2021-06-03T13:18:29.223394Z",
     "shell.execute_reply": "2021-06-03T13:18:29.223813Z"
    },
    "papermill": {
     "duration": 0.022003,
     "end_time": "2021-06-03T13:18:29.223933",
     "exception": false,
     "start_time": "2021-06-03T13:18:29.201930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(fold):\n",
    "    def get_result(result_df):\n",
    "        preds = result_df['preds'].values\n",
    "        labels = result_df[CFG.target_col].values\n",
    "        score = get_score(labels, preds)\n",
    "        LOGGER.info(f'Score: {score:<.5f}')\n",
    "    \n",
    "    def get_result2(result_df):\n",
    "        preds = result_df['preds'].values\n",
    "        labels = result_df[CFG.target_col].values\n",
    "        matrix = get_confusion_matrix(labels, preds)\n",
    "        print('TN', matrix[0,0])\n",
    "        print('FP', matrix[0,1])\n",
    "        print('FN', matrix[1,0])\n",
    "        print('TP', matrix[1,1])\n",
    "    \n",
    "    # train \n",
    "    train_folds = folds.query(f'fold!={fold}').reset_index(drop=True)\n",
    "    valid_folds = folds.query(f'fold=={fold}').reset_index(drop=False)\n",
    "    oof_df, scores = train_loop(train_folds, valid_folds)\n",
    "    # CV result\n",
    "    LOGGER.info(f\"========== CV ==========\")\n",
    "    get_result(oof_df)\n",
    "    get_result2(oof_df)\n",
    "    # save result\n",
    "    oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)\n",
    "    plt.plot([i for i in range(CFG.epochs)], scores)\n",
    "    plt.title('valid score')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:29.255472Z",
     "iopub.status.busy": "2021-06-03T13:18:29.254659Z",
     "iopub.status.idle": "2021-06-03T13:33:30.200216Z",
     "shell.execute_reply": "2021-06-03T13:33:30.199729Z"
    },
    "papermill": {
     "duration": 900.96416,
     "end_time": "2021-06-03T13:33:30.200354",
     "exception": false,
     "start_time": "2021-06-03T13:18:29.236194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5          [-1, 128, 56, 56]           8,192\n",
      "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
      "              ReLU-7          [-1, 128, 56, 56]               0\n",
      "            Conv2d-8          [-1, 128, 56, 56]           4,608\n",
      "       BatchNorm2d-9          [-1, 128, 56, 56]             256\n",
      "             ReLU-10          [-1, 128, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          32,768\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
      "             ReLU-19          [-1, 128, 56, 56]               0\n",
      "           Conv2d-20          [-1, 128, 56, 56]           4,608\n",
      "      BatchNorm2d-21          [-1, 128, 56, 56]             256\n",
      "             ReLU-22          [-1, 128, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          32,768\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
      "             ReLU-29          [-1, 128, 56, 56]               0\n",
      "           Conv2d-30          [-1, 128, 56, 56]           4,608\n",
      "      BatchNorm2d-31          [-1, 128, 56, 56]             256\n",
      "             ReLU-32          [-1, 128, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          32,768\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 256, 56, 56]          65,536\n",
      "      BatchNorm2d-38          [-1, 256, 56, 56]             512\n",
      "             ReLU-39          [-1, 256, 56, 56]               0\n",
      "           Conv2d-40          [-1, 256, 28, 28]          18,432\n",
      "      BatchNorm2d-41          [-1, 256, 28, 28]             512\n",
      "             ReLU-42          [-1, 256, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-50          [-1, 256, 28, 28]             512\n",
      "             ReLU-51          [-1, 256, 28, 28]               0\n",
      "           Conv2d-52          [-1, 256, 28, 28]          18,432\n",
      "      BatchNorm2d-53          [-1, 256, 28, 28]             512\n",
      "             ReLU-54          [-1, 256, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-60          [-1, 256, 28, 28]             512\n",
      "             ReLU-61          [-1, 256, 28, 28]               0\n",
      "           Conv2d-62          [-1, 256, 28, 28]          18,432\n",
      "      BatchNorm2d-63          [-1, 256, 28, 28]             512\n",
      "             ReLU-64          [-1, 256, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-70          [-1, 256, 28, 28]             512\n",
      "             ReLU-71          [-1, 256, 28, 28]               0\n",
      "           Conv2d-72          [-1, 256, 28, 28]          18,432\n",
      "      BatchNorm2d-73          [-1, 256, 28, 28]             512\n",
      "             ReLU-74          [-1, 256, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 512, 28, 28]         262,144\n",
      "      BatchNorm2d-80          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-81          [-1, 512, 28, 28]               0\n",
      "           Conv2d-82          [-1, 512, 14, 14]          73,728\n",
      "      BatchNorm2d-83          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-84          [-1, 512, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 512, 14, 14]         524,288\n",
      "      BatchNorm2d-92          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-93          [-1, 512, 14, 14]               0\n",
      "           Conv2d-94          [-1, 512, 14, 14]          73,728\n",
      "      BatchNorm2d-95          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-96          [-1, 512, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-102          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-103          [-1, 512, 14, 14]               0\n",
      "          Conv2d-104          [-1, 512, 14, 14]          73,728\n",
      "     BatchNorm2d-105          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-106          [-1, 512, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         524,288\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-112          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-113          [-1, 512, 14, 14]               0\n",
      "          Conv2d-114          [-1, 512, 14, 14]          73,728\n",
      "     BatchNorm2d-115          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-116          [-1, 512, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         524,288\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-122          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-123          [-1, 512, 14, 14]               0\n",
      "          Conv2d-124          [-1, 512, 14, 14]          73,728\n",
      "     BatchNorm2d-125          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-126          [-1, 512, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         524,288\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-132          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-133          [-1, 512, 14, 14]               0\n",
      "          Conv2d-134          [-1, 512, 14, 14]          73,728\n",
      "     BatchNorm2d-135          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-136          [-1, 512, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         524,288\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141         [-1, 1024, 14, 14]       1,048,576\n",
      "     BatchNorm2d-142         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-143         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-144           [-1, 1024, 7, 7]         294,912\n",
      "     BatchNorm2d-145           [-1, 1024, 7, 7]           2,048\n",
      "            ReLU-146           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153           [-1, 1024, 7, 7]       2,097,152\n",
      "     BatchNorm2d-154           [-1, 1024, 7, 7]           2,048\n",
      "            ReLU-155           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-156           [-1, 1024, 7, 7]         294,912\n",
      "     BatchNorm2d-157           [-1, 1024, 7, 7]           2,048\n",
      "            ReLU-158           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163           [-1, 1024, 7, 7]       2,097,152\n",
      "     BatchNorm2d-164           [-1, 1024, 7, 7]           2,048\n",
      "            ReLU-165           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-166           [-1, 1024, 7, 7]         294,912\n",
      "     BatchNorm2d-167           [-1, 1024, 7, 7]           2,048\n",
      "            ReLU-168           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "         Flatten-174                 [-1, 2048]               0\n",
      "SelectAdaptivePool2d-175                 [-1, 2048]               0\n",
      "          Linear-176                 [-1, 1000]       2,049,000\n",
      "          ResNet-177                 [-1, 1000]               0\n",
      "================================================================\n",
      "Total params: 25,028,904\n",
      "Trainable params: 25,028,904\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 361.82\n",
      "Params size (MB): 95.48\n",
      "Estimated Total Size (MB): 457.87\n",
      "----------------------------------------------------------------\n",
      "Epoch: [1][1/192] Data 0.366 (0.366) Elapsed 0m 0s (remain 2m 42s) Loss: 7.1064(7.1064) Grad: 48.6470  \n",
      "Epoch: [1][101/192] Data 0.000 (0.004) Elapsed 0m 15s (remain 0m 13s) Loss: 0.2543(1.7392) Grad: 9.7622  \n",
      "Epoch: [1][192/192] Data 0.000 (0.002) Elapsed 0m 29s (remain 0m 0s) Loss: 0.4854(1.0767) Grad: 13.2381  \n",
      "EVAL: [1/49] Data 0.133 (0.133) Elapsed 0m 0s (remain 0m 8s) Loss: 0.3713(0.3713) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 1.0767  avg_val_loss: 0.3834  time: 32s\n",
      "Epoch 1 - Accuracy: 0.8693107932379714\n",
      "Epoch 1 - Save Best Score: 0.8693 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [49/49] Data 0.000 (0.003) Elapsed 0m 2s (remain 0m 0s) Loss: 0.3555(0.3834) \n",
      "Epoch: [2][1/192] Data 0.303 (0.303) Elapsed 0m 0s (remain 1m 25s) Loss: 0.2946(0.2946) Grad: 9.4966  \n",
      "Epoch: [2][101/192] Data 0.000 (0.003) Elapsed 0m 17s (remain 0m 15s) Loss: 0.1718(0.2970) Grad: 6.1443  \n",
      "Epoch: [2][192/192] Data 0.000 (0.002) Elapsed 0m 33s (remain 0m 0s) Loss: 0.3563(0.2871) Grad: 8.8820  \n",
      "EVAL: [1/49] Data 0.166 (0.166) Elapsed 0m 0s (remain 0m 10s) Loss: 0.3844(0.3844) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.2871  avg_val_loss: 0.3881  time: 36s\n",
      "Epoch 2 - Accuracy: 0.8517555266579974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [49/49] Data 0.000 (0.004) Elapsed 0m 2s (remain 0m 0s) Loss: 0.5595(0.3881) \n",
      "Epoch: [3][1/192] Data 0.360 (0.360) Elapsed 0m 0s (remain 1m 37s) Loss: 0.3593(0.3593) Grad: 11.1564  \n",
      "Epoch: [3][101/192] Data 0.000 (0.004) Elapsed 0m 18s (remain 0m 17s) Loss: 0.0931(0.2622) Grad: 4.2378  \n",
      "Epoch: [3][192/192] Data 0.000 (0.002) Elapsed 0m 34s (remain 0m 0s) Loss: 0.4375(0.2465) Grad: 11.6814  \n",
      "EVAL: [1/49] Data 0.119 (0.119) Elapsed 0m 0s (remain 0m 8s) Loss: 0.3321(0.3321) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.2465  avg_val_loss: 0.3451  time: 37s\n",
      "Epoch 3 - Accuracy: 0.8790637191157347\n",
      "Epoch 3 - Save Best Score: 0.8791 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [49/49] Data 0.000 (0.003) Elapsed 0m 2s (remain 0m 0s) Loss: 0.5486(0.3451) \n",
      "Epoch: [4][1/192] Data 0.336 (0.336) Elapsed 0m 0s (remain 1m 33s) Loss: 0.2575(0.2575) Grad: 10.6247  \n",
      "Epoch: [4][101/192] Data 0.000 (0.004) Elapsed 0m 17s (remain 0m 15s) Loss: 0.0908(0.2313) Grad: 5.9541  \n",
      "Epoch: [4][192/192] Data 0.000 (0.002) Elapsed 0m 35s (remain 0m 0s) Loss: 0.4726(0.2130) Grad: 16.0058  \n",
      "EVAL: [1/49] Data 0.137 (0.137) Elapsed 0m 0s (remain 0m 8s) Loss: 0.3592(0.3592) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.2130  avg_val_loss: 0.3320  time: 38s\n",
      "Epoch 4 - Accuracy: 0.8881664499349805\n",
      "Epoch 4 - Save Best Score: 0.8882 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [49/49] Data 0.000 (0.003) Elapsed 0m 2s (remain 0m 0s) Loss: 0.7793(0.3320) \n",
      "Epoch: [5][1/192] Data 0.326 (0.326) Elapsed 0m 0s (remain 1m 33s) Loss: 0.1346(0.1346) Grad: 7.7823  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.033439,
     "end_time": "2021-06-03T13:33:30.267988",
     "exception": false,
     "start_time": "2021-06-03T13:33:30.234549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 921.862366,
   "end_time": "2021-06-03T13:33:31.832533",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-03T13:18:09.970167",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
