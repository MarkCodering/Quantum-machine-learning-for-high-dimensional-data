{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011267,
     "end_time": "2021-06-03T13:18:16.507530",
     "exception": false,
     "start_time": "2021-06-03T13:18:16.496263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Credit\n",
    "\n",
    "This notebook is based on the following notebook by @yasufuminakama. I would like to take this opportunity to thank him.\n",
    "\n",
    "Please vote for his notebook as well.\n",
    "\n",
    "https://www.kaggle.com/yasufuminakama/cassava-resnext50-32x4d-starter-training\n",
    "\n",
    "# Summary of this notebook\n",
    "\n",
    "In this notebook, we are gonna build the nocall detector. (0:nocall, 1:somebird singing)\n",
    "\n",
    "The output of the models would be probability value.\n",
    "\n",
    "# input & output of this notebook\n",
    "\n",
    "[input]\n",
    "\n",
    "freefield1010 data\n",
    "\n",
    "https://www.kaggle.com/startjapan/ff1010bird-duration7\n",
    "\n",
    "[output]\n",
    "\n",
    "Nocall detector models are outputted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:16.537460Z",
     "iopub.status.busy": "2021-06-03T13:18:16.536974Z",
     "iopub.status.idle": "2021-06-03T13:18:16.540823Z",
     "shell.execute_reply": "2021-06-03T13:18:16.540348Z"
    },
    "papermill": {
     "duration": 0.023365,
     "end_time": "2021-06-03T13:18:16.540951",
     "exception": false,
     "start_time": "2021-06-03T13:18:16.517586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:16.566791Z",
     "iopub.status.busy": "2021-06-03T13:18:16.566088Z",
     "iopub.status.idle": "2021-06-03T13:18:17.801738Z",
     "shell.execute_reply": "2021-06-03T13:18:17.801136Z"
    },
    "papermill": {
     "duration": 1.250811,
     "end_time": "2021-06-03T13:18:17.801878",
     "exception": false,
     "start_time": "2021-06-03T13:18:16.551067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CFG:\n",
    "    print_freq=100\n",
    "    num_workers=4\n",
    "    model_name= 'resnext50_32x4d'\n",
    "    dim=(128, 281)\n",
    "    scheduler='CosineAnnealingWarmRestarts'\n",
    "    epochs=10\n",
    "    #lr=1e-4\n",
    "    lr=0.001\n",
    "    T_0=10 # for CosineAnnealingWarmRestarts\n",
    "    min_lr=5e-7 # for CosineAnnealingWarmRestarts\n",
    "    batch_size=32\n",
    "    weight_decay=1e-6\n",
    "    max_grad_norm=1000\n",
    "    seed=42\n",
    "    target_size=2\n",
    "    target_col='hasbird'\n",
    "    n_fold = 5\n",
    "    pretrained = True\n",
    "    #device = 'cpu'\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:17.830157Z",
     "iopub.status.busy": "2021-06-03T13:18:17.829448Z",
     "iopub.status.idle": "2021-06-03T13:18:18.811434Z",
     "shell.execute_reply": "2021-06-03T13:18:18.810978Z"
    },
    "papermill": {
     "duration": 0.999064,
     "end_time": "2021-06-03T13:18:18.811555",
     "exception": false,
     "start_time": "2021-06-03T13:18:17.812491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  hasbird\n",
      "0     0          1151\n",
      "      1           387\n",
      "1     0          1151\n",
      "      1           387\n",
      "2     0          1151\n",
      "      1           387\n",
      "3     0          1151\n",
      "      1           387\n",
      "4     0          1151\n",
      "      1           387\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('/home/next/Quantum/Quantum-machine-learning-for-high-dimensional-data/input/rich_metadata.csv')\n",
    "train.loc[train['hasbird']==0, 'filepath'] = '/home/next/Quantum/Quantum-machine-learning-for-high-dimensional-data/input/nocall/' + train.query('hasbird==0')['filename'] + '.npy'\n",
    "train.loc[train['hasbird']==1, 'filepath'] = '/home/next/Quantum/Quantum-machine-learning-for-high-dimensional-data/input/bird/' + train.query('hasbird==1')['filename'] + '.npy'\n",
    "\n",
    "train = train.dropna().reset_index(drop=True)\n",
    "\n",
    "folds = train.copy()\n",
    "Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[CFG.target_col])):\n",
    "    folds.loc[val_index, 'fold'] = int(n)\n",
    "folds['fold'] = folds['fold'].astype(int)\n",
    "print(folds.groupby(['fold', CFG.target_col]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:18.844986Z",
     "iopub.status.busy": "2021-06-03T13:18:18.844348Z",
     "iopub.status.idle": "2021-06-03T13:18:28.957198Z",
     "shell.execute_reply": "2021-06-03T13:18:28.956722Z"
    },
    "papermill": {
     "duration": 10.134555,
     "end_time": "2021-06-03T13:18:28.957330",
     "exception": false,
     "start_time": "2021-06-03T13:18:18.822775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "\n",
    "import timm\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:28.992535Z",
     "iopub.status.busy": "2021-06-03T13:18:28.991939Z",
     "iopub.status.idle": "2021-06-03T13:18:28.998314Z",
     "shell.execute_reply": "2021-06-03T13:18:28.997883Z"
    },
    "papermill": {
     "duration": 0.028265,
     "end_time": "2021-06-03T13:18:28.998451",
     "exception": false,
     "start_time": "2021-06-03T13:18:28.970186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "def get_confusion_matrix(y_true, y_pred):\n",
    "    return confusion_matrix(y_true, y_pred)\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f'[{name}] start')\n",
    "    yield\n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:29.031990Z",
     "iopub.status.busy": "2021-06-03T13:18:29.031227Z",
     "iopub.status.idle": "2021-06-03T13:18:29.033990Z",
     "shell.execute_reply": "2021-06-03T13:18:29.033586Z"
    },
    "papermill": {
     "duration": 0.022696,
     "end_time": "2021-06-03T13:18:29.034100",
     "exception": false,
     "start_time": "2021-06-03T13:18:29.011404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_paths = df['filepath'].values\n",
    "        self.labels = df['hasbird'].values\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_paths[idx]\n",
    "        file_path = file_name\n",
    "        image = np.load(file_path)\n",
    "        image = image.transpose(1,2,0)\n",
    "        image = np.squeeze(image)\n",
    "        image = np.stack((image,)*3, -1)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        label = torch.tensor(self.labels[idx]).long()\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:29.065650Z",
     "iopub.status.busy": "2021-06-03T13:18:29.064968Z",
     "iopub.status.idle": "2021-06-03T13:18:29.067798Z",
     "shell.execute_reply": "2021-06-03T13:18:29.067278Z"
    },
    "papermill": {
     "duration": 0.021515,
     "end_time": "2021-06-03T13:18:29.067897",
     "exception": false,
     "start_time": "2021-06-03T13:18:29.046382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_transforms(*, data):\n",
    "    \n",
    "    if data == 'train':\n",
    "        return A.Compose([\n",
    "            A.Resize(CFG.dim[0], CFG.dim[1]),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.augmentations.transforms.JpegCompression(p=0.5),\n",
    "            A.augmentations.transforms.ImageCompression(p=0.5, compression_type=A.augmentations.transforms.ImageCompression.ImageCompressionType.WEBP),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    elif data == 'valid':\n",
    "        return A.Compose([\n",
    "            A.Resize(CFG.dim[0], CFG.dim[1]),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af7c554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomResNext(nn.Module):\n",
    "    def __init__(self, model_name='resnext50_32x4d', pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        n_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a938703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, CrossEntropyLoss, MSELoss\n",
    "from torch.optim import LBFGS\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.utils import algorithm_globals\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap, ZFeatureMap, EfficientSU2\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "# Set seed for random generators\n",
    "algorithm_globals.random_seed = 42\n",
    "\n",
    "# we decompose the circuit for the QNN to avoid additional data copying\n",
    "# Define and create QNN\n",
    "nq=1\n",
    "def create_qnn():\n",
    "    feature_map = ZFeatureMap(nq, reps=2)\n",
    "    ansatz = RealAmplitudes(nq, reps=1)\n",
    "    qc = QuantumCircuit(nq)\n",
    "    qc.compose(feature_map, inplace=True)\n",
    "    qc.compose(ansatz, inplace=True)\n",
    "    \n",
    "    # REMEMBER TO SET input_gradients=True FOR ENABLING HYBRID GRADIENT BACKPROP\n",
    "    qnn = EstimatorQNN(\n",
    "        circuit=qc,\n",
    "        input_params=feature_map.parameters,\n",
    "        weight_params=ansatz.parameters,\n",
    "        input_gradients=True,\n",
    "    )\n",
    "    return qnn\n",
    "\n",
    "\n",
    "qnn = create_qnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59643d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from torch import cat, no_grad, manual_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "431e8931",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumCustomResNext(nn.Module):\n",
    "    def __init__(self, model_name='resnext50_32x4d', pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        self.fc = nn.Linear(512, nq)    \n",
    "        self.qnn = TorchConnector(qnn)\n",
    "        self.fc2 = nn.Linear(1, 1)  # 1-dimensional output from QNN\n",
    "        #self.fc2 = nn.Linear(pow(2, nq), CFG.target_size)\n",
    "        \n",
    "        # Remove fully connected layer and last two blocks\n",
    "        self.model.fc = nn.Identity()\n",
    "        self.model.layer4 = nn.Identity()\n",
    "        self.model.layer3 = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.qnn(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return cat((x, 1 - x), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:29.145766Z",
     "iopub.status.busy": "2021-06-03T13:18:29.144984Z",
     "iopub.status.idle": "2021-06-03T13:18:29.147597Z",
     "shell.execute_reply": "2021-06-03T13:18:29.147086Z"
    },
    "papermill": {
     "duration": 0.035666,
     "end_time": "2021-06-03T13:18:29.147696",
     "exception": false,
     "start_time": "2021-06-03T13:18:29.112030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (images, labels) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        y_preds = model(images)\n",
    "        loss = criterion(y_preds, labels)\n",
    "        # record loss\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        global_step += 1\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  .format(\n",
    "                   epoch+1, step+1, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses,\n",
    "                   remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                   grad_norm=grad_norm,\n",
    "                   ))\n",
    "    return losses.avg\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (images, labels) in enumerate(valid_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(images)\n",
    "        loss = criterion(y_preds, labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        # record accuracy\n",
    "        preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(\n",
    "                   step+1, len(valid_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses,\n",
    "                   remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                   ))\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions\n",
    "\n",
    "def inference(model, states, test_loader, device):\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    probs = []\n",
    "    for i, (images) in tk0:\n",
    "        images = images.to(device)\n",
    "        avg_preds = []\n",
    "        for state in states:\n",
    "            model.load_state_dict(state['model'])\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "        avg_preds = np.mean(avg_preds, axis=0)\n",
    "        probs.append(avg_preds)\n",
    "    probs = np.concatenate(probs)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:29.187429Z",
     "iopub.status.busy": "2021-06-03T13:18:29.186604Z",
     "iopub.status.idle": "2021-06-03T13:18:29.189566Z",
     "shell.execute_reply": "2021-06-03T13:18:29.189044Z"
    },
    "papermill": {
     "duration": 0.029536,
     "end_time": "2021-06-03T13:18:29.189694",
     "exception": false,
     "start_time": "2021-06-03T13:18:29.160158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "def train_loop(train_folds, valid_folds):\n",
    "\n",
    "    LOGGER.info(f\"========== training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    train_dataset = TrainDataset(train_folds, \n",
    "                                 transform=get_transforms(data='train'))\n",
    "    valid_dataset = TrainDataset(valid_folds, \n",
    "                                 transform=get_transforms(data='valid'))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, \n",
    "                              batch_size=CFG.batch_size, \n",
    "                              shuffle=False, \n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, \n",
    "                              batch_size=CFG.batch_size, \n",
    "                              shuffle=False, \n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "    \n",
    "    def get_scheduler(optimizer):\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = QuantumCustomResNext(CFG.model_name, pretrained=True)\n",
    "    #model = CustomResNext(CFG.model_name, pretrained=True)\n",
    "    model.to(CFG.device)\n",
    "    \n",
    "    optimizer = Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay, amsgrad=False)\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    criterion = nn.NLLLoss()\n",
    "    best_score = 0.\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    summary(model, (3, 128, 128))\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for epoch in range(CFG.epochs):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, CFG.device)\n",
    "        \n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, CFG.device)\n",
    "        valid_labels = valid_folds[CFG.target_col].values\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        score = get_score(valid_labels, preds.argmax(1))\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Accuracy: {score}')\n",
    "        \n",
    "        scores.append(score)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(), \n",
    "                        'preds': preds},\n",
    "                        OUTPUT_DIR+f'{CFG.model_name}_best.pth')\n",
    "    \n",
    "    check_point = torch.load(OUTPUT_DIR+f'{CFG.model_name}_best.pth')\n",
    "    valid_folds[[str(c) for c in range(CFG.target_size)]] = check_point['preds']\n",
    "    valid_folds['preds'] = check_point['preds'].argmax(1)\n",
    "\n",
    "    return valid_folds, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:29.221823Z",
     "iopub.status.busy": "2021-06-03T13:18:29.221144Z",
     "iopub.status.idle": "2021-06-03T13:18:29.223394Z",
     "shell.execute_reply": "2021-06-03T13:18:29.223813Z"
    },
    "papermill": {
     "duration": 0.022003,
     "end_time": "2021-06-03T13:18:29.223933",
     "exception": false,
     "start_time": "2021-06-03T13:18:29.201930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(fold):\n",
    "    def get_result(result_df):\n",
    "        preds = result_df['preds'].values\n",
    "        labels = result_df[CFG.target_col].values\n",
    "        score = get_score(labels, preds)\n",
    "        LOGGER.info(f'Score: {score:<.5f}')\n",
    "    \n",
    "    def get_result2(result_df):\n",
    "        preds = result_df['preds'].values\n",
    "        labels = result_df[CFG.target_col].values\n",
    "        matrix = get_confusion_matrix(labels, preds)\n",
    "        print('TN', matrix[0,0])\n",
    "        print('FP', matrix[0,1])\n",
    "        print('FN', matrix[1,0])\n",
    "        print('TP', matrix[1,1])\n",
    "    \n",
    "    # train \n",
    "    train_folds = folds.query(f'fold!={fold}').reset_index(drop=True)\n",
    "    valid_folds = folds.query(f'fold=={fold}').reset_index(drop=False)\n",
    "    oof_df, scores = train_loop(train_folds, valid_folds)\n",
    "    # CV result\n",
    "    LOGGER.info(f\"========== CV ==========\")\n",
    "    get_result(oof_df)\n",
    "    get_result2(oof_df)\n",
    "    # save result\n",
    "    oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)\n",
    "    plt.plot([i for i in range(CFG.epochs)], scores)\n",
    "    plt.title('valid score')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:18:29.255472Z",
     "iopub.status.busy": "2021-06-03T13:18:29.254659Z",
     "iopub.status.idle": "2021-06-03T13:33:30.200216Z",
     "shell.execute_reply": "2021-06-03T13:33:30.199729Z"
    },
    "papermill": {
     "duration": 900.96416,
     "end_time": "2021-06-03T13:33:30.200354",
     "exception": false,
     "start_time": "2021-06-03T13:18:29.236194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
      "              ReLU-3           [-1, 64, 64, 64]               0\n",
      "         MaxPool2d-4           [-1, 64, 32, 32]               0\n",
      "            Conv2d-5          [-1, 128, 32, 32]           8,192\n",
      "       BatchNorm2d-6          [-1, 128, 32, 32]             256\n",
      "              ReLU-7          [-1, 128, 32, 32]               0\n",
      "            Conv2d-8          [-1, 128, 32, 32]           4,608\n",
      "       BatchNorm2d-9          [-1, 128, 32, 32]             256\n",
      "         Identity-10          [-1, 128, 32, 32]               0\n",
      "             ReLU-11          [-1, 128, 32, 32]               0\n",
      "         Identity-12          [-1, 128, 32, 32]               0\n",
      "           Conv2d-13          [-1, 256, 32, 32]          32,768\n",
      "      BatchNorm2d-14          [-1, 256, 32, 32]             512\n",
      "           Conv2d-15          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-16          [-1, 256, 32, 32]             512\n",
      "             ReLU-17          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-18          [-1, 256, 32, 32]               0\n",
      "           Conv2d-19          [-1, 128, 32, 32]          32,768\n",
      "      BatchNorm2d-20          [-1, 128, 32, 32]             256\n",
      "             ReLU-21          [-1, 128, 32, 32]               0\n",
      "           Conv2d-22          [-1, 128, 32, 32]           4,608\n",
      "      BatchNorm2d-23          [-1, 128, 32, 32]             256\n",
      "         Identity-24          [-1, 128, 32, 32]               0\n",
      "             ReLU-25          [-1, 128, 32, 32]               0\n",
      "         Identity-26          [-1, 128, 32, 32]               0\n",
      "           Conv2d-27          [-1, 256, 32, 32]          32,768\n",
      "      BatchNorm2d-28          [-1, 256, 32, 32]             512\n",
      "             ReLU-29          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-30          [-1, 256, 32, 32]               0\n",
      "           Conv2d-31          [-1, 128, 32, 32]          32,768\n",
      "      BatchNorm2d-32          [-1, 128, 32, 32]             256\n",
      "             ReLU-33          [-1, 128, 32, 32]               0\n",
      "           Conv2d-34          [-1, 128, 32, 32]           4,608\n",
      "      BatchNorm2d-35          [-1, 128, 32, 32]             256\n",
      "         Identity-36          [-1, 128, 32, 32]               0\n",
      "             ReLU-37          [-1, 128, 32, 32]               0\n",
      "         Identity-38          [-1, 128, 32, 32]               0\n",
      "           Conv2d-39          [-1, 256, 32, 32]          32,768\n",
      "      BatchNorm2d-40          [-1, 256, 32, 32]             512\n",
      "             ReLU-41          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-42          [-1, 256, 32, 32]               0\n",
      "           Conv2d-43          [-1, 256, 32, 32]          65,536\n",
      "      BatchNorm2d-44          [-1, 256, 32, 32]             512\n",
      "             ReLU-45          [-1, 256, 32, 32]               0\n",
      "           Conv2d-46          [-1, 256, 16, 16]          18,432\n",
      "      BatchNorm2d-47          [-1, 256, 16, 16]             512\n",
      "         Identity-48          [-1, 256, 16, 16]               0\n",
      "             ReLU-49          [-1, 256, 16, 16]               0\n",
      "         Identity-50          [-1, 256, 16, 16]               0\n",
      "           Conv2d-51          [-1, 512, 16, 16]         131,072\n",
      "      BatchNorm2d-52          [-1, 512, 16, 16]           1,024\n",
      "           Conv2d-53          [-1, 512, 16, 16]         131,072\n",
      "      BatchNorm2d-54          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-55          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-56          [-1, 512, 16, 16]               0\n",
      "           Conv2d-57          [-1, 256, 16, 16]         131,072\n",
      "      BatchNorm2d-58          [-1, 256, 16, 16]             512\n",
      "             ReLU-59          [-1, 256, 16, 16]               0\n",
      "           Conv2d-60          [-1, 256, 16, 16]          18,432\n",
      "      BatchNorm2d-61          [-1, 256, 16, 16]             512\n",
      "         Identity-62          [-1, 256, 16, 16]               0\n",
      "             ReLU-63          [-1, 256, 16, 16]               0\n",
      "         Identity-64          [-1, 256, 16, 16]               0\n",
      "           Conv2d-65          [-1, 512, 16, 16]         131,072\n",
      "      BatchNorm2d-66          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-67          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-68          [-1, 512, 16, 16]               0\n",
      "           Conv2d-69          [-1, 256, 16, 16]         131,072\n",
      "      BatchNorm2d-70          [-1, 256, 16, 16]             512\n",
      "             ReLU-71          [-1, 256, 16, 16]               0\n",
      "           Conv2d-72          [-1, 256, 16, 16]          18,432\n",
      "      BatchNorm2d-73          [-1, 256, 16, 16]             512\n",
      "         Identity-74          [-1, 256, 16, 16]               0\n",
      "             ReLU-75          [-1, 256, 16, 16]               0\n",
      "         Identity-76          [-1, 256, 16, 16]               0\n",
      "           Conv2d-77          [-1, 512, 16, 16]         131,072\n",
      "      BatchNorm2d-78          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-79          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-80          [-1, 512, 16, 16]               0\n",
      "           Conv2d-81          [-1, 256, 16, 16]         131,072\n",
      "      BatchNorm2d-82          [-1, 256, 16, 16]             512\n",
      "             ReLU-83          [-1, 256, 16, 16]               0\n",
      "           Conv2d-84          [-1, 256, 16, 16]          18,432\n",
      "      BatchNorm2d-85          [-1, 256, 16, 16]             512\n",
      "         Identity-86          [-1, 256, 16, 16]               0\n",
      "             ReLU-87          [-1, 256, 16, 16]               0\n",
      "         Identity-88          [-1, 256, 16, 16]               0\n",
      "           Conv2d-89          [-1, 512, 16, 16]         131,072\n",
      "      BatchNorm2d-90          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-91          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-92          [-1, 512, 16, 16]               0\n",
      "         Identity-93          [-1, 512, 16, 16]               0\n",
      "         Identity-94          [-1, 512, 16, 16]               0\n",
      "AdaptiveAvgPool2d-95            [-1, 512, 1, 1]               0\n",
      "          Flatten-96                  [-1, 512]               0\n",
      "SelectAdaptivePool2d-97                  [-1, 512]               0\n",
      "         Identity-98                  [-1, 512]               0\n",
      "           ResNet-99                  [-1, 512]               0\n",
      "          Linear-100                    [-1, 1]             513\n",
      "  TorchConnector-101                    [-1, 1]               2\n",
      "          Linear-102                    [-1, 1]               2\n",
      "================================================================\n",
      "Total params: 1,412,933\n",
      "Trainable params: 1,412,933\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 99.02\n",
      "Params size (MB): 5.39\n",
      "Estimated Total Size (MB): 104.60\n",
      "----------------------------------------------------------------\n",
      "Epoch: [1][1/192] Data 0.489 (0.489) Elapsed 0m 1s (remain 4m 21s) Loss: -1.0967(-1.0967) Grad: 49.7054  \n",
      "Epoch: [1][101/192] Data 0.000 (0.005) Elapsed 0m 34s (remain 0m 30s) Loss: -1.3683(-1.0112) Grad: 20.6920  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 921.862366,
   "end_time": "2021-06-03T13:33:31.832533",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-03T13:18:09.970167",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
